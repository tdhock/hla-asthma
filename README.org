** TODOs

- survival prediction (coxnet or AFT?)
- nonlinear models like SVM, KNN, ctree, cforest.
- augmented feature space (age, SNPs)
- unscaled model so we can interpret weights.

** 18 Mar 2016

[[file:figure-glmnet.R]] produces a plot which shows glmnet model
selection curves: binomial deviance on the validation set, and AUC on
the train/test sets.

[[file:figure-glmnet-train.png]]

** 14 Mar 2016

[[file:figure-glmnet.R]] produces a plot of variable importance in terms
of number of folds for which each variable was selected in 10-fold CV.

[[file:figure-glmnet.png]]

[[file:figure-test-error.R]] produces two plots:

Facetted roc curves (one for each test fold) suggest that
glmnet.balanced model (not glmnet.one) is better than random guessing.

[[file:figure-test-error-roc.png]]

The error metrics below show that the glmnet.balanced model is
definitely learning a weak pattern that can predict asthma/healthy
status better than random guessing (which is what major.class and
glmnet.one do).

[[file:figure-test-error.png]]

** 11 Mar 2016

[[file:hla.R]] Extract feature matrix of HLA allele counts and model
probabilities from test.RData.
